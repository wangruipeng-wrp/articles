---
title: Java并发：重排序规则
abbrlink: 41133
description: 程序最终的执行顺序是由 CPU 处理的，做为 Java 程序员更应该关心的是重排序的结果，而不是重排序的过程。
date: 2022-08-25 10:17:57
categories:
  - Java
  - 并发
---

关于重排序的一些概念性问题在[Java 内存模型（JMM）](https://www.wrp.cool/posts/41498/#有序性是怎么产生并发问题的)中 *「有序性是怎么产生并发问题的」* 一节有详细介绍。

程序最终的执行顺序是由 CPU 处理的，做为 Java 程序员更应该关心的是重排序的结果，而不是重排序的过程。

具体的在什么情况下会发生重排序，又是按照一个什么样的规则去重排序，这些问题应该交给 CPU 去处理，我们应该关心的是我们写的程序被重排序后是怎么样的。

# 数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：

|名称|代码示例|说明|
|:--|:--|:--|
|写后读|a = 1;b = a;|写一个变量之后，再读这个位置。|
|写后写|a = 1;a = 2;|写一个变量之后，再写这个变量。|
|读后写|a = b;b = 1;|读一个变量之后，再写这个变量。|

上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。

前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。

> 注意：这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。

# as-if-serial 语义

as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。

为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例：

```java
double pi   = 3.14;         //A
double r    = 1.0;          //B
double area = pi * r * r;   //C
```

上面三个操作的数据依赖关系如下图所示：

![重排序数据依赖关系](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/重排序数据依赖关系.png)

如上图所示，A 和 C 之间存在数据依赖关系，同时 B 和 C 之间也存在数据依赖关系。因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 的前面（C 排到 A 和 B 的前面，程序的结果将会被改变）。但 A 和 B 之间没有数据依赖关系，编译器和处理器可以重排序 A 和 B 之间的执行顺序。下图是该程序的两种执行顺序：

![重排序后可能的依赖关系](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/重排序后可能的依赖关系.png)

as-if-serial 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。

# 程序顺序规则

根据 happens- before 的程序顺序规则，上面计算圆的面积的示例代码存在三个 happens- before 关系：

- A happens- before B；
- B happens- before C；
- A happens- before C；

这里的第 3 个 happens- before 关系，是根据 happens- before 的传递性推导出来的。

这里 A happens-before B，但实际执行时 B 却可以排在 A 之前执行（看上面的重排序后的执行顺序）。实际上如果 A happens-before B，JMM 并不要求 A 一定要在 B 之前执行。JMM 仅仅要求前一个操作（执行的结果）对后一个操作可见。这里操作 A 的执行结果不需要对操作 B 可见；而且重排序操作 A 和操作 B 后的执行结果，与操作 A 和操作 B 按 happens-before 顺序执行的结果一致。在这种情况下，JMM 会认为这种重排序并不非法（not illegal），JMM 允许这种重排序。

在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从 happens- before 的定义我们可以看出，JMM 同样遵从这一目标。

# 重排序对多线程的影响

现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码：

```java
class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1;                   //1
        flag = true;             //2
    }

    public void reader() {
        if (flag) {                //3
            int i =  a * a;        //4
            ……
        }
    }
}
```

flag 变量是个标记，用来标识变量 a 是否已被写入。这里假设有两个线程 A 和 B，A 首先执行 writer() 方法，随后 B 线程接着执行 reader() 方法。线程 B 在执行操作 4 时，能否看到线程 A 在操作 1 对共享变量 a 的写入？

答案是：不一定能看到。

由于操作 1 和操作 2 没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作 3 和操作 4 没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作 1 和操作 2 重排序时，可能会产生什么效果? 请看下面的程序执行时序图：

![java-jmm-8](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/java-jmm-8.png)

如上图所示，操作 1 和操作 2 做了重排序。程序执行时，线程 A 首先写标记变量 flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量 a。此时，变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！

下面再让我们看看，当操作 3 和操作 4 重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作 3 和操作 4 重排序后，程序的执行时序图：

![java-jmm-9](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/java-jmm-9.png)

在程序中，操作 3 和操作 4 存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程 B 的处理器可以提前读取并计算 a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作 3 的条件判断为真时，就把该计算结果写入变量 i 中。

从图中我们可以看出，猜测执行实质上对操作 3 和 4 做了重排序。重排序在这里破坏了多线程程序的语义！

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as-if-serial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。

> 虽然重排序的一些具体的发生过程并不是我们关心的重点，但作为程序员，求知好学也是应该的不是吗。下面的部分不感兴趣的同学跳过即可。

# 为什么会发生重排序

重排序分为真重排序和伪重排序，真重排序就像是在[Java 内存模型（JMM）](https://www.wrp.cool/posts/41498/)中的 *「有序性是怎么产生并发问题的」* 所介绍的：**在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。**伪重排序正是接下来所要介绍的：

> 由于现代的处理器使用写缓冲区来临时保存向内存写入的数据，这对内存操作的执行顺序产生重要的影响。

**写缓冲区的优点：**

- 保证指令流水线持续运行，可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟
- 通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用

**写缓冲区的缺点：**每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！请看下面示例：

```java
// Processor A
a = 1; //A1  
x = b; //A2

// Processor B
b = 2; //B1  
y = a; //B2

// 初始状态：a = b = 0；处理器允许执行后得到结果：x = y = 0
```

假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示：

![伪重排序执行时序图](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/伪重排序执行时序图.png)

以下面的这种时序执行时，程序就会得到 x = y = 0 的结果：

1. 处理器 A 和处理器 B 同时把共享变量写入自己的写缓冲区（A1，B1）
2. 处理器 A 和处理器 B 同时从内存中读取另一个共享变量（A2，B2）
3. 处理器 A 和处理器 B 刷自己写缓冲区中的脏数据到内存中（A3，B3）

从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1->A2，但内存操作实际发生的顺序却是：A2->A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。

这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。

为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类：

| 屏障类型 | 指令示例 | 说明 |
|:--|:--|:--|
LoadLoad Barriers | Load1; LoadLoad; Load2 | 确保 Load1 数据装载，之前于 Load2 及所有后续装载指令的装载。
StoreStore Barriers | Store1; StoreStore; Store2 | 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。
LoadStore Barriers | Load1; LoadStore; Store2 | 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。
StoreLoad Barriers | Store1; StoreLoad; Load2 | 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Load2 及所有后续装载指令的装载。

StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。

StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。

---

> **巨人的肩膀：**
> 
>  - [深入理解Java内存模型](https://www.infoq.cn/minibook/java_memory_model)