---
title: Java并发：并发容器
abbrlink: 3103
date: 2022-08-04 21:50:58
description: 从并发容器的发展历史开始，优秀如 ConcurrentHashMap 这样的代码绝不是一朝一夕就可以完成的。
categories:
  - Java
  - 并发
---

> 看并发容器的发展历史其实也反映了一个软件的发展历史，很明显大多数软件在研发的初期都是比较粗糙的，这也是由市场的性质所决定的，前期如果投入了过多的时间跟精力，那么一旦这款软件不被市场所接受，那全都白费了。并发容器的发展历程跟这如出一辙。

早期的 jdk 中的并发容器只有 Vector 和 Hashtable，初期的设计这两种并发容器的效率并不理想，这两个并发容器的实现和早期的 ArrayList 和 HashMap 几乎一样，只是在其中的一些可能会导致并发不安全的方法上加了 synchronized 关键字用来同步。将 synchronized 加在方法上等于是锁住了整个实例对象。这样的设计是方便了开发人员，几乎是最少的成本实现了并发容器的功能，但是效率上就堪忧了。

再到后来的 Collections 提供的同步工具类：`Collections.synchronizedList(new ArrayList<>())`。这种方式来创建并发容器，实际上也只是把 synchronized 从方法签名上转移到了方法内部。锁的粒度更细了一些，但也不是那么优秀。

这两种方式虽然都不是很优秀，但也是一个发展的过程。接下来才是正文。

{% note default %}
**为什么普通容器不安全**
{% endnote %}

普通容器没有对写操作和扩容做同步操作，如果多个线程同时写到了同一个位置或者扩容的话，只有一个线程的修改能被保存下来。原理就像是不安全的 `i++` 一样。

甚至在 HashMap 中多线程同时扩容还会造成 `自己.next = 自己` 造成 CPU100% 的情况。具体情况可以参考[这篇文章](https://coolshell.cn/articles/9606.html)

# ConcurrentHashMap

Java8 中 的 ConcurrentHashMap 数据结构示意图：

![并发容器-1](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/并发容器-1.png)

第一排被框起来的一个个小方块就是 Node 节点类，这里要跟 Java7 的 Segment 区分好，jdk1.7 的 Segment 通过继承 ReentrantLock 来加锁，也就是每次锁住的是一个 Segment 实例，相当于是所有的 Segment 加起来才是完整的 ConcurrentHashMap，在一定程度上提高了并发度。一开始我认为 Java8 的 Node 跟 Java7 的 Segment 一样是不可扩容的，但这里的 Node 是可以扩容的，要区分开。

正常来说数据都是存放在 Node 数组里面的，如果发生了 hash 冲突，那会从 Node 往后再拉一个链表出来，把冲突的数据放在后面。当这个链表的长度达到 8 并且 Node 数组的长度超过 64，那么就会把链表转换成红黑树来存储冲突数据。

概括一下 ConcurrentHashMap 中的数据结构为：`数组 + 链表 + 红黑树`

## put() 方法流程

方法定义：

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}

// 接下来要分析的内容，onlyIfAbsent：元素是否可重复
final V putVal(K key, V value, boolean onlyIfAbsent) {
    ...
}
```

首先就是一些常规流程，比如判空、获取新元素 hash 值、以及记录链表长度用于后面判断是否需要链表转红黑树操作。

```java
if (key == null || value == null) throw new NullPointerException();
int hash = spread(key.hashCode());
int binCount = 0;
```

根据前面的 ConcurrentHashMap 的数据结构，put() 方法添加的新元素可能会：
- 落在 Node 节点上；
- 落在 Node 拉出来的链表上；
- 落在由链表转换的红黑树上。

### 新元素落在 Node 上

```java
// 自旋，确保肯定能插入成功
for (Node<K,V>[] tab = table;;) {
    Node<K,V> f; int n, i, fh;
    // 找到 hash 对应位置的 Node 发现为 null，于是此次 put() 操作应该创建新 Node
    if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
        // CAS 把新 Node 放进去
        if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value, null)))
            break;
    } else {
        // 数据落在链表或者红黑树上的情况，下面的分析将从此处开始
        // 数据落地后判断是否将链表转换成红黑树，该部分分析从此处开始
    }
}
return null;
```

### 新元素落在链表上

```java
// 从此处开始才锁起来，锁的对象是被操作的整个 Node 节点
synchronized (f) {
    /* 因为刚刚没有锁起来，在这里可能刚刚拿到的 f 节点已经被改了
     * 再做一次判断看看有没有被改，如果被改了那就自旋重来一次 */

    /* 关于这里的这个 if 说一点点点我自己的想法吧，
     * 如果是我写这个 if 我会这么写：if (tabAt(tab, i) != f) continue;
     * 首先这么写可以少一层缩进，代码上看起来会舒服一些
     * 另外下面还有一个判断是否要转换成红黑树的操作，直接 continue 的话可以少一次判断，
     * 少这一次判断不是为了省这一点点的判断的性能，而是此时如果其他线程增加了节点导致需要转换红黑树，
     * 那么哪个判断就进去了，虽然 treeifyBin() 方法也是线程安全的，但本来这不该是当前线程去做的
     */
    
    if (tabAt(tab, i) == f) {
        // fh：头节点的 hash 值，大于 0 说明是链表
        if (fh >= 0) {
            binCount = 1;
            // 循环找到链表最后一个位置
            for (Node<K,V> e = f;; ++binCount) {
                K ek;
                // 找到了重复的键，判断是否覆盖
                if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) {
                    oldVal = e.val;
                    if (!onlyIfAbsent)
                        e.val = value;
                    break;
                }
                Node<K,V> pred = e;
                // 走到了链表尾，将新元素挂在链表尾部。
                if ((e = e.next) == null) {
                    pred.next = new Node<K,V>(hash, key, value, null);
                    break;
                }
            }
        }
        // 数据落在红黑树的情况，下面的分析将从此处开始
    }
}
```

### 新元素落在红黑树上

```java
// 头节点是红黑树节点
else if (f instanceof TreeBin) {
    Node<K,V> p;
    binCount = 2;
    // 调用红黑树的插值方法插入新节点
    if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
        oldVal = p.val;
        if (!onlyIfAbsent)
            p.val = value;
    }
}
```

### 是否链转红

```java
// 链表长度超过8转换成红黑树
if (binCount != 0) {
    if (binCount >= TREEIFY_THRESHOLD)
        // 走到这里还不一定会转换成红黑树
        // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
        treeifyBin(tab, i);
    if (oldVal != null)
        return oldVal;
    break;
}
```

{% note default %}
**为什么链表转红黑树的阈值是8？**
{% endnote %}

根据泊松分布，如果 hash 函数的设计没问题的话，链表长度超过8的概率还不足千万分之一，已经是及其小的概率了。千万不要觉得8这个数字不是那么大就觉得 ConcurrentHashMap 会经常发生链表转红黑树的情况。

### put() 流程小结

1. 准备工作：判断 key value 不为空、计算 hash 值等。
2. 如果：新元素落在新节点上。那么：CAS 新增节点。
3. 如果：新元素落在链表上。那么：遍历链表插入新元素。
4. 如果：新元素落在红黑树上。那么：调用红黑树方法插入新节点。
5. 判断是否需要将链表转换为红黑树

关于整个 put() 方法的工作流程这里还只是很表面的分析，这里还有几个重量级问题：第一个是初始化，第二个是扩容，第三个是帮助数据迁移。

## get() 方法流程

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    int h = spread(key.hashCode());

    // 判断 ConcurrentHashMap 是否已经初始化完毕，以及对应位置的元素是否已经添加
    if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) {
        // 头节点是不是我们想要的节点
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        // 如果头结点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树
        else if (eh < 0)
            // find 方法根据 e 的具体实现（ForwardingNode 或 TreeBin）而调用对应方法
            return (p = e.find(h, key)) != null ? p.val : null;
        // 不是红黑树也不是头节点，那肯定是链表，遍历取出即可
        while ((e = e.next) != null) {
            if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
```

**get() 流程小结：**

1. 计算 hash 值
2. 如果：值在 Node 节点中。那么：直接返回。
3. 如果：正在扩容或者值在红黑树中。那么：调用对应方法找到 val 返回
4. 如果：都不是。那么：肯定是链表，遍历返回 val
5. 找不到，返回 null

# CopyOnWriteArrayList

先简单介绍一下 Cpoy On Write 思想吧。Cpoy On Write 就是一种写时复制的操作，字面上意思也很明确：写操作复制。执行写入操作时先复制一份副本，在副本上写入，再将指针指向被修改的副本。优点是在读取的时候不需要加锁，并且读写冲突不会抢锁，仅在写写冲突的时候会抢锁。缺点也很明显，多线程同时写的话会对内存造成比较大的压力；并且保证不了数据的实施一致性，只能保证数据的最终一致性，因为读操作拿到的数据可能不是最新的数据。

其多线程并发安全由内部数据不可变保证，不可变指的是每次修改都是在副本上修改，所以读取的数据永远不会改变。

{% note default %}
**Cpoy On Write 在迭代中的应用：**
{% endnote %}

一些没有 Cpoy On Write 能力的集合（ArrayList）在迭代的时候会发生什么事情：

```java
public static void main(String[] args) {
    List<Integer> list = new ArrayList<>(Arrays.asList(1, 2, 3, 4, 5));
    for (Integer i : list) 
        list.add(6);
}

// main 方法抛出异常：
// java.util.ConcurrentModificationException
```

抛出异常的原因也很简单，ArrayList 不允许在迭代的过程中新增或者删除元素。为什么不允许呢？

因为迭代的过程中新增或删除元素会导致迭代访问元素顺序错乱或者死循环跟下标越界问题。比如：访问到第5个元素的时候把第1个元素删了，此时所有元素往前移了一个位置，那原来的第六个元素的访问就被跳过了。

foreach 循环依赖了由 ArrayList 提供的 Iterator 对象。Iterator 对象维护了一个 expectedModCount 变量，这个变量记录了 Iterator 对象初始化时 ArrayList 发生了多少次增加或删除元素的操作，ArrayList 每次增加或删除元素都会维护 modCount 变量。于是每次迭代调用 iterator.next() 时都会检查 expectedModCount 与 modCount 是否相等，不相等则抛出 java.util.ConcurrentModificationException 异常。

上面的代码如果使用 CopyOnWriteArrayList 实现就不会抛出此异常：

```java
public static void main(String[] args) {
    List<Integer> list = new CopyOnWriteArrayList<>(Arrays.asList(1, 2, 3, 4, 5));
    for (Integer i : list) {
        list.add(6);
        System.out.print(i + "  ");
    }
    System.out.print("\n" + list);
}

// main 方法输出：
// 1  2  3  4  5  
// [1, 2, 3, 4, 5, 6, 6, 6, 6, 6]
```

结果也是很明显，符合 Copy On Write 原则。新增元素时在副本上增加，不会影响到正在迭代的数据，指针切换后仍然遍历的是旧数据。

# 阻塞队列

阻塞队列（BlockingQueue）通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。下图是对这个原理的阐述：

![阻塞队列示意图](https://wrp-blog-image.oss-cn-beijing.aliyuncs.com/blog-images/阻塞队列示意图.png)

在这个示意图中，`Thread 1` 代表生产线程，`Thread 2` 代表了消费线程。

生产线程将会持续生产新对象放到阻塞队列中，直到队列达到它所能容纳的临界点。达到临界点再往队列插入新对象时会发生阻塞，直到消费线程从队列中拿走一个对象。消费线程会一直在阻塞队列中拿出对象，如果队列为空的话，消费线程会发生阻塞，直到一个生产线程往队列中插入一个新对象。

每当有新对象入队时就会唤醒一个消费者线程；每当有一个对象出队时就会唤醒一个生产者线程。

{% note default %}
**使用示例：ArrayBlockingQueue**
{% endnote %}

ArrayBlockingQueue 是一个有界的阻塞队列，也是一个 FIFO 队列，其底层由一个不可扩容的数组实现，意味着同一时间能够存储元素数量是有上限的，数组容易在初始化时设定。

```java
class Producer implements Runnable {
    private final BlockingQueue<Integer> queue;
    public Producer(BlockingQueue<Integer> queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            queue.put(1);
            queue.put(2);
            queue.put(3);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

class Consumer implements Runnable{
    private final BlockingQueue<Integer> queue;
    public Consumer(BlockingQueue<Integer> queue) {
        this.queue = queue;
    }

    public void run() {
        try {
            System.out.println(queue.take());
            System.out.println(queue.take());
            System.out.println(queue.take());
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

public static void main(String[] args) {
    BlockingQueue<Integer> queue = new ArrayBlockingQueue<>(3);

    Producer producer = new Producer(queue);
    Consumer consumer = new Consumer(queue);

    new Thread(producer).start();
    new Thread(consumer).start();
}
```

还有一些其他阻塞队列在实际开发中应当视情况选择合适的队列使用比如：延迟队列 DelayQueue、链阻塞队列 LinkedBlockingQueue、具有优先级的阻塞队列 PriorityBlockingQueue、同步队列 SynchronousQueue 等等。

---

> **巨人的肩膀：**
> 
> - [Java7/8 中的 HashMap 和 ConcurrentHashMap 全解析](https://www.javadoop.com/post/hashmap)